{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# импорт библиотек и ключа"
      ],
      "metadata": {
        "id": "GQkRCc8a_F1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bLZk0zeV5QiF",
        "outputId": "a859b995-e847-455c-d861-f532ab080216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.72.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Downloading openai-1.72.0-py3-none-any.whl (643 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.9/643.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.70.0\n",
            "    Uninstalling openai-1.70.0:\n",
            "      Successfully uninstalled openai-1.70.0\n",
            "Successfully installed openai-1.72.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai.api_resources'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4fc66696f58e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install tiktoken'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai.api_resources'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "!pip install openai --upgrade\n",
        "import json\n",
        "!pip install pandas\n",
        "!pip install chardet\n",
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "from openai.api_resources import image\n",
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\"\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "J_OOEkGvkV5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *transform_trb*"
      ],
      "metadata": {
        "id": "kv8_udhh-i8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_trb(trb:dict,o:str,c:str):\n",
        "    res_str = \"\"\n",
        "    op_va = trb[o]\n",
        "    cal_va = trb[c]\n",
        "\n",
        "    op_i = 0\n",
        "    cal_i = 0\n",
        "\n",
        "    while op_i < len(op_va) and cal_i < len(cal_va):\n",
        "        if op_va[op_i][\"start\"] < cal_va[cal_i][\"start\"]:\n",
        "            speech = op_va[op_i][\"text\"]\n",
        "            op_i += 1\n",
        "            if speech:\n",
        "                res_str += f\"o: {speech}\\n\"\n",
        "        else:\n",
        "            speech = cal_va[cal_i][\"text\"]\n",
        "            cal_i += 1\n",
        "            if speech:\n",
        "                res_str += f\"c: {speech}\\n\"\n",
        "\n",
        "    return res_str[:-1]\n",
        "\n",
        "#data = {\"c\": [{\"stop\": 1.4, \"text\": \"До скорой встречи!\", \"start\": 0.5}, {\"stop\": 26.3, \"text\": \"Дарья, Дмитрий, Дарья, здравствуйте, извините. Я, получается, подавал документы через ВИЛСОГИ. Ваш ВУЗ принял мои документы, получается, поставил приоритет с 4 группы на 1 в конкурсной программе. Я хотел спросить, для участия в конкурсной программе можно мне как-то узнать информацию о том, что там будет и когда, и как мне войти в личный кабинет на сайте M2C?\", \"start\": 5.1}, {\"stop\": 43.9, \"text\": \"Личного кабинета где?\", \"start\": 42.5}, {\"stop\": 49.5, \"text\": \"А мне нету на вашем файтере личного кабинета.\", \"start\": 47.1}, {\"stop\": 64.1, \"text\": \"Я подал документы, мне нужно потерять то, что у меня в составе в личном кабинете.\", \"start\": 58.6}, {\"stop\": 76.8, \"text\": \"Извините, можете еще раз повторить? Вас очень плохо слышно.\", \"start\": 74.2}, {\"stop\": 86.7, \"text\": \"Вопрос в том, что значит смена приоритета?\", \"start\": 82.0}, {\"stop\": 102.9, \"text\": \"Нет, я в очередных госслугах не написал, что ВОЗ поменяла приоритет с 4 на 1.\", \"start\": 97.8}, {\"stop\": 120.5, \"text\": \"Сейчас, секундочку, информация технологии и коммуникации вроде бы.\", \"start\": 115.9}, {\"stop\": 133.1, \"text\": \"с какой?\", \"start\": 132.6}, {\"stop\": 142.9, \"text\": \"дублируйте пожалуйста.\", \"start\": 142.2}, {\"stop\": 153.6, \"text\": \"информатика и искусственная техника. Вот такой.\", \"start\": 150.0}, {\"stop\": 170.6, \"text\": \"секундочку подождите.\", \"start\": 165.1}, {\"stop\": 175.7, \"text\": \"Номер, да?\", \"start\": 174.5}, {\"stop\": 179.6, \"text\": \"ВПП 206.\", \"start\": 178.9}, {\"stop\": 183.4, \"text\": \"ВПП 22.\", \"start\": 182.7}, {\"stop\": 187.4, \"text\": \"\", \"start\": 186.2}, {\"stop\": 191.4, \"text\": \"\", \"start\": 190.8}, {\"stop\": 199.9, \"text\": \"Реально.\", \"start\": 199.5}, {\"stop\": 223.2, \"text\": \"бюджет платный.\", \"start\": 222.3}, {\"stop\": 240.7, \"text\": \"До какого цифра можно запечатать договор?\", \"start\": 239.0}, {\"stop\": 257.5, \"text\": \"Да, 125.\", \"start\": 256.0}, {\"stop\": 267.5, \"text\": \"По 70.\", \"start\": 266.7}, {\"stop\": 277.5, \"text\": \"Я подавал через Вузапеде, там минимальные баллы писало, и на госслугах тоже пишут минимальные баллы, я по ним прохожу.\", \"start\": 270.7}, {\"stop\": 282.8, \"text\": \"Говорю, меня приняли и получили.\", \"start\": 280.6}, {\"stop\": 290.7, \"text\": \"У меня по сумме примерно 125.\", \"start\": 288.7}, {\"stop\": 311.5, \"text\": \"Но я подавал именно наочно, на госслугах. У меня спокойно там прошел, все нормально. И вот на госслугах пишут, что вас ВУЗ сам поменял. Наочно все нормально там.\", \"start\": 300.5}, {\"stop\": 316.6, \"text\": \"А если стать...\", \"start\": 315.4}, {\"stop\": 326.8, \"text\": \"Такой вопрос, а не может ли телеграмма притяжиться к конкурсам? Как это влияет?\", \"start\": 321.2}, {\"stop\": 349.3, \"text\": \"Ладно, хорошо, спасибо.\", \"start\": 348.2}, {\"stop\": 357.4, \"text\": \"Продолжение следует...\", \"start\": 356.6}, {\"stop\": 362.5, \"text\": \"Ну, хорошо, Лен.\", \"start\": 360.1}], \"o\": [{\"stop\": 5.6, \"text\": \"Добрый день, приемная комиссия МТУС, меня зовут Дерри. Скажите, пожалуйста, как я могу к вам обращаться?\", \"start\": 1.2}, {\"stop\": 41.9, \"text\": \"Чтобы зайти в личный кабинет на нашем сайте, вам нужно написать нам на почту pksobachka.ru о том, что вы подавали документы через госуслуги, и уточнить ваш логин и пароль от личного кабинета.\", \"start\": 24.2}, {\"stop\": 47.5, \"text\": \"на нашем сайте.\", \"start\": 44.9}, {\"stop\": 56.2, \"text\": \"Ну вот, вам нужно точить логин и пароль. Он делается, если я не ошибаюсь, то всем, кто подает документы.\", \"start\": 50.4}, {\"stop\": 80.9, \"text\": \"Нет, вы должны уточнить у нас на почте. Подскажите, пожалуйста, какой еще вопрос вас интересует? Да, хотела уточнить, какой еще вопрос вас интересует?\", \"start\": 64.7}, {\"stop\": 97.9, \"text\": \"Верна, я понимаю, что вы смотрите сейчас на нашем сайте ранжированные списки?\", \"start\": 85.4}, {\"stop\": 101.6, \"text\": \"\", \"start\": 101.2}, {\"stop\": 116.2, \"text\": \"По госуслугам подсказать не смогу, а подскажите, пожалуйста, какое направление Вы выбрали для поступления?\", \"start\": 103.3}, {\"stop\": 138.5, \"text\": \"Инфокоммуникационные технологии системы связи. А какой факультет выбрали? РИТ или СИС? Какой факультет выбрали? РИТ или СИС? Там беспроводная связь есть и проводная связь.\", \"start\": 122.0}, {\"stop\": 149.4, \"text\": \"Угу.\", \"start\": 140.6}, {\"stop\": 154.4, \"text\": \"Ммм...\", \"start\": 153.2}, {\"stop\": 160.4, \"text\": \"Можете подсказать свой стил\", \"start\": 156.2}, {\"stop\": 163.6, \"text\": \"Да.\", \"start\": 163.2}, {\"stop\": 169.6, \"text\": \"Субтитры добавил DimaTorzok\", \"start\": 168.4}, {\"stop\": 173.9, \"text\": \"Ну что, Костича?\", \"start\": 172.4}, {\"stop\": 181.4, \"text\": \"номер снялся 206\", \"start\": 176.0}, {\"stop\": 190.7, \"text\": \"213\", \"start\": 184.2}, {\"stop\": 210.9, \"text\": \"А вы подавали оригинал документов или копии? Оригинал. Хорошо, поняла.\", \"start\": 192.8}, {\"stop\": 215.3, \"text\": \"на очень информное обучение, верно?\", \"start\": 212.8}, {\"stop\": 220.0, \"text\": \"Почтный бюджет\", \"start\": 218.8}, {\"stop\": 226.9, \"text\": \"Угу. Всё, хорошо, я вас поняла.\", \"start\": 224.1}, {\"stop\": 237.0, \"text\": \"А подскажите, пожалуйста, тогда, когда планируете заключать договор?\", \"start\": 232.9}, {\"stop\": 246.9, \"text\": \"Рассматриваете очную основу для поступления?\", \"start\": 244.0}, {\"stop\": 270.3, \"text\": \"А если я не ошибаюсь, то у вас показано, что 125 баллов за ЕГЭ или вступительное испытание. На заключение договора на очную платную форму обучения идет от 150 баллов. 150.\", \"start\": 249.6}, {\"stop\": 297.9, \"text\": \"У нас есть минимальные баллы по каждому предмету и также по сумме предметов. Это 150 минимальный. То есть вы можете рассмотреть поступление, да. Вы можете рассмотреть очень заочную форму обучения или заочную.\", \"start\": 278.8}, {\"stop\": 308.5, \"text\": \"Удачи!\", \"start\": 306.7}, {\"stop\": 321.6, \"text\": \"Да, но у нас очередное платное зачисление идет только от 150 баллов.\", \"start\": 312.4}, {\"stop\": 359.8, \"text\": \"Оно может, но у нас максимально за индивидуальное достижение можно добавить 10 баллов. То есть даже если добавить вам 10 баллов, это будет 135, а нужно 150 все-таки. Да, что вы, не за что. Если будут вопросы, звоните, с радостью подскажем. Хорошего дня. До свидания.\", \"start\": 326.1}, {\"stop\": 362.5, \"text\": \"Вот так.\", \"start\": 361.6}]}\n",
        "#result = transform_trb(data, \"o\", \"c\")\n",
        "#print(result)"
      ],
      "metadata": {
        "id": "6QmU4Yh-5UHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/input_file/trbs.csv', 'r', newline='') as infile, open('/content/input_file/result_trbs.csv', 'w', newline='') as outfile:\n",
        "    reader = csv.reader(infile)\n",
        "    writer = csv.writer(outfile)\n",
        "    headers = next(reader)\n",
        "\n",
        "    writer.writerow(['trb_id', 'trb', 'duration'])\n",
        "\n",
        "    for row in reader:\n",
        "        trb_id, trb, duration = row\n",
        "        try:\n",
        "            trb_data = json.loads(trb)\n",
        "            result_trb = transform_trb(trb_data, \"o\", \"c\")\n",
        "            writer.writerow([trb_id, result_trb, duration])\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing JSON  {trb_id}: {e}\")\n"
      ],
      "metadata": {
        "id": "cwn4i8NDrrcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# подсчет токенов"
      ],
      "metadata": {
        "id": "63lU0H1w-zuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Тебе будет предоставлена транскрибированная речь оператора из телефонного звонка в формате джейсон на русском языке, которая отделена тройными кавычками и пронумерованные вопросы, которые  тоже отделены тройными кавычками. Телефонный звонок происходит между оператором представляющим ВУЗ и абитуриентом или его представителем. Транскрибация может быть не точной и содержать ошибки. Тебе нужно проанализировать звонок и ответить на вопросы в формате + или -. Если у тебя не получается точно ответить на вопросы по какой то причине, то напиши что ты не можешь ответить на вопросы и укажи по какой причине. После вопроса могут быть прописаны в скобках примеры ожидаемых фраз.\n",
        "\n",
        "  Пример вывода:\n",
        "  1_+\n",
        "  2_-\n",
        "  3_+\n",
        "  4_-\n",
        "  5_-\n",
        "  6_+\n",
        "  7_+\n",
        "  8_+\n",
        "  9_-\n",
        "  10_+\n",
        "  \"\"\"\n",
        "system = \"\"\"Вы полезный помощник, который дает ответы на вопросы по транскрибации речи телефонного звонка.\"\"\"\n",
        "#code = prompt + \"\\n\" + messages[0][\"content\"]\n",
        "#print(code)\n",
        "\n",
        "# функция для подсчета количество токенов\n",
        "def get_token_count(code):\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    token_count = len(enc.encode(code)) + 11\n",
        "    return token_count\n"
      ],
      "metadata": {
        "id": "Cn8qYH_x-qVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# получение ответов на вопросы"
      ],
      "metadata": {
        "id": "Z3lY5Y_A-7UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df = pd.read_csv(\"/content/input_file/questions.csv\")\n",
        "question_text = \" \".join(questions_df[\"question\"])\n",
        "\n",
        "def get_answers(prompt, trb_id, question_id):\n",
        "    code = prompt + \"\\n\" + system\n",
        "    token_count = get_token_count(code)\n",
        "    if token_count > 4096 - 400:\n",
        "        model_name = \"gpt-3.5-turbo-16k\"\n",
        "    else:\n",
        "        model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "    code = code.replace(\"\\n\", \"\")\n",
        "\n",
        "    code = code.replace('\"', '\\\\\"')\n",
        "\n",
        "    message = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_name,\n",
        "        #messages=[{\"role\": \"user\", \"content\": code}],\n",
        "        messages=message,\n",
        "        temperature=0.5,\n",
        "        max_tokens=400,\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message['content']\n",
        "    # answer = content.strip()[-1]  # + or -\n",
        "    # if answer not in '+-':\n",
        "    #     answer = 'N'\n",
        "    return content\n",
        "\n"
      ],
      "metadata": {
        "id": "3kFD7lUoOW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "trbs_df = pd.read_csv('/content/input_file/result_trbs.csv')\n",
        "questions_df = pd.read_csv('/content/input_file/questions.csv')\n",
        "\n",
        "with open('/content/output_file/prompt_question.csv', 'w', encoding='utf-8', newline='') as result_file:\n",
        "    result_writer = csv.writer(result_file)\n",
        "\n",
        "    result_writer.writerow(['trb_id', 'question_id', 'answer'])\n",
        "\n",
        "    for trb_row in trbs_df.itertuples(index=False):\n",
        "        time.sleep(1)\n",
        "        trb_id, trb, duration = trb_row\n",
        "\n",
        "        all_questions = []\n",
        "\n",
        "        for question_row in questions_df.itertuples(index=False):\n",
        "            question_id, question_text = question_row\n",
        "            all_questions.append(f\"{question_id}-{question_text}\")\n",
        "\n",
        "        all_questions_str = '\\n'.join(all_questions)\n",
        "        full_prompt = prompt + \"\\n\\\"\\\"\\\"\\n\" + trb + \"\\n\\\"\\\"\\\"\\n\\n\\\"\\\"\\\"\\n\" + all_questions_str + \"\\n\\\"\\\"\\\"\"\n",
        "\n",
        "        answers = get_answers(full_prompt, trb_id, None)\n",
        "        answers_list = answers.strip().split(\"\\n\")\n",
        "\n",
        "        for question_id, answer in zip(range(1, len(all_questions) + 1), answers_list):\n",
        "            result_writer.writerow([trb_id, question_id, answer])\n",
        "\n",
        "print(\"Data has been processed to prompt_question.csv.\")\n"
      ],
      "metadata": {
        "id": "6ki5OYzy1v90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оценка ответов"
      ],
      "metadata": {
        "id": "TjQTbLVyZKT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/input_file/questions.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    questions = [row[1] for row in reader]\n",
        "\n",
        "with open('/content/output_file/full_prompt.txt', 'w', encoding='utf-8') as output_file:\n",
        "    output_file.write('\\n'.join(questions))\n",
        "    output_file.write('\\n')\n",
        "    output_file.write(prompt)"
      ],
      "metadata": {
        "id": "_emRYLhjWTq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_question_df = pd.read_csv('/content/output_file/prompt_question.csv')\n",
        "\n",
        "def strip_number(value):\n",
        "    if isinstance(value, str) and value.strip().endswith('+'):\n",
        "        return '+'\n",
        "    elif isinstance(value, str) and value.strip().endswith('-'):\n",
        "        return '-'\n",
        "    else:\n",
        "        return value\n",
        "prompt_question_df['ground_truth'] = prompt_question_df['answer'].apply(strip_number)\n",
        "\n",
        "\n",
        "prompt_question_df.drop(columns=['answer'], inplace=True)\n",
        "\n",
        "prompt_question_df.to_csv('/content/output_file/prompt_question.csv', index=False)\n"
      ],
      "metadata": {
        "id": "WhPNKiTeIO-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_question_df = pd.read_csv('/content/output_file/prompt_question.csv')\n",
        "questions_labels_df = pd.read_csv('/content/input_file/questions_labels.csv')\n",
        "\n",
        "results = []\n",
        "\n",
        "def compare_and_store(question_id):\n",
        "    prompt_question_filtered = prompt_question_df[prompt_question_df['question_id'] == question_id]\n",
        "    questions_labels_filtered = questions_labels_df[questions_labels_df['question_id'] == question_id]\n",
        "\n",
        "    plus_count = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for index, row in prompt_question_filtered.iterrows():\n",
        "        trb_id = row['trb_id']\n",
        "        prompt_gt = row['ground_truth']\n",
        "        labels_gt = questions_labels_filtered[questions_labels_filtered['trb_id'] == trb_id]['ground_truth'].values[0]\n",
        "\n",
        "        result = {\n",
        "            'trb_id': trb_id,\n",
        "            'question_id': question_id,\n",
        "            'ground_truth': '+' if prompt_gt == labels_gt else '-'\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        total_count += 1\n",
        "        if result['ground_truth'] == '+':\n",
        "            plus_count += 1\n",
        "\n",
        "    return f'{plus_count}/{total_count}'\n",
        "\n",
        "number_results = []\n",
        "for question_id in range(1, 11):\n",
        "    compare_and_store(question_id)\n",
        "    number_result = {\n",
        "        'question_id': question_id,\n",
        "        'result': compare_and_store(question_id)\n",
        "    }\n",
        "    number_results.append(number_result)\n",
        "\n",
        "number_df = pd.DataFrame(number_results)\n",
        "number_df.to_csv('/content/output_file/number.csv', index=False)\n"
      ],
      "metadata": {
        "id": "TjjxphfAGrBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Расчет precision и recall"
      ],
      "metadata": {
        "id": "Z9NcoJII4RW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_question_df = pd.read_csv('/content/output_file/prompt_question.csv')\n",
        "questions_labels_df = pd.read_csv('/content/input_file/questions_labels.csv')\n",
        "\n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "def compare_and_store_metrics(question_id):\n",
        "    prompt_question_filtered = prompt_question_df[prompt_question_df['question_id'] == question_id]\n",
        "    questions_labels_filtered = questions_labels_df[questions_labels_df['question_id'] == question_id]\n",
        "\n",
        "    true_positive_count = 0\n",
        "    false_positive_count = 0\n",
        "    false_negative_count = 0\n",
        "    true_negative_count = 0\n",
        "    no_answer_count = 0\n",
        "\n",
        "    for index, row in prompt_question_filtered.iterrows():\n",
        "        trb_id = row['trb_id']\n",
        "        prompt_gt = row['ground_truth']\n",
        "        labels_gt = questions_labels_filtered[questions_labels_filtered['trb_id'] == trb_id]['ground_truth'].values[0]\n",
        "\n",
        "        result = {\n",
        "            'trb_id': trb_id,\n",
        "            'question_id': question_id,\n",
        "            'prompt_gt': prompt_gt,\n",
        "            'labels_gt': labels_gt\n",
        "        }\n",
        "        comparison_results.append(result)\n",
        "\n",
        "        if prompt_gt == '+' and labels_gt == '+':\n",
        "            true_positive_count += 1\n",
        "        elif prompt_gt == '+' and labels_gt == '-':\n",
        "            false_positive_count += 1\n",
        "        elif prompt_gt == '-' and labels_gt == '+':\n",
        "            false_negative_count += 1\n",
        "        elif prompt_gt == '-' and labels_gt == '-':\n",
        "            true_negative_count += 1\n",
        "        else:\n",
        "            no_answer_count += 1\n",
        "\n",
        "    return true_positive_count, false_positive_count, false_negative_count, true_negative_count, no_answer_count\n",
        "\n",
        "metrics_results = []\n",
        "for question_id in range(1, 11):\n",
        "    tp, fp, fn, tn, no_answer = compare_and_store_metrics(question_id)\n",
        "    total_count = tp + fp + fn + tn\n",
        "    metrics_result = {\n",
        "        'question_id': question_id,\n",
        "        'tp_count': tp,\n",
        "        'fp_count': fp,\n",
        "        'fn_count': fn,\n",
        "        'tn_count': tn,\n",
        "        'no_answer_count': no_answer,\n",
        "        'total_count': total_count\n",
        "    }\n",
        "    metrics_results.append(metrics_result)\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_results)\n",
        "metrics_df.to_csv('/content/output_file/metrics.csv', index=False)\n"
      ],
      "metadata": {
        "id": "YNdfbGBNEczf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = pd.read_csv('/content/output_file/metrics.csv')\n",
        "\n",
        "metrics_df['precision'] = metrics_df['tp_count'] / (metrics_df['tp_count'] + metrics_df['fp_count'])\n",
        "metrics_df['recall'] = metrics_df['tp_count'] / (metrics_df['tp_count'] + metrics_df['fn_count'])\n",
        "\n",
        "metrics_df.to_csv('/content/output_file/metrics.csv', index=False)"
      ],
      "metadata": {
        "id": "lpQvUbEdHW4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Всего вопросов: 50\n",
        "- Количество совпадений + и -: 47\n"
      ],
      "metadata": {
        "id": "WSz-dfw6eVpZ"
      }
    }
  ]
}